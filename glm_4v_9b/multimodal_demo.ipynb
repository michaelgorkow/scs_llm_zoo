{
 "metadata": {
  "kernelspec": {
   "display_name": "Streamlit Notebook",
   "name": "streamlit"
  }
 },
 "nbformat_minor": 5,
 "nbformat": 4,
 "cells": [
  {
   "cell_type": "markdown",
   "id": "01b98b46-36f4-4778-b0f5-c30ef5773861",
   "metadata": {
    "name": "cell6",
    "collapsed": false
   },
   "source": "# Multimodal Model in Snowflake"
  },
  {
   "cell_type": "markdown",
   "id": "dc574e25-80f6-4425-ae78-1c010dd74595",
   "metadata": {
    "name": "cell7",
    "collapsed": false
   },
   "source": "## Imports"
  },
  {
   "cell_type": "code",
   "id": "3775908f-ca36-4846-8f38-5adca39217f2",
   "metadata": {
    "language": "python",
    "name": "cell1",
    "collapsed": false
   },
   "source": "from snowflake.snowpark.functions import call_udf, call_builtin, col, lit, object_construct\n\n# Import python packages\nimport streamlit as st\nimport pandas as pd\n\n# We can also use Snowpark for our analyses!\nfrom snowflake.snowpark.context import get_active_session\nsession = get_active_session()",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "5344e5de-3dda-4bdf-b1a0-db8d1591eaa9",
   "metadata": {
    "name": "cell16",
    "collapsed": false
   },
   "source": "# Example: Describe a list of Images"
  },
  {
   "cell_type": "markdown",
   "id": "58733fb6-6c86-4f5b-9500-8b7de26f1c3e",
   "metadata": {
    "name": "cell8",
    "collapsed": false
   },
   "source": "## Retrieve Data"
  },
  {
   "cell_type": "code",
   "id": "8ec91f4a-3bd2-4bbe-aea3-7b5f6b0bb4bd",
   "metadata": {
    "language": "python",
    "name": "cell2",
    "collapsed": false
   },
   "outputs": [],
   "source": "files_df = session.sql('SELECT * FROM DIRECTORY(@IMAGE_FILES)').filter(col('RELATIVE_PATH').startswith('celebs/')).limit(2).cache_result()\nfiles_df",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "e035d7da-b248-44d4-b92a-a33c9d8a2eda",
   "metadata": {
    "name": "cell9",
    "collapsed": false
   },
   "source": "## Define Prompt"
  },
  {
   "cell_type": "code",
   "id": "d992f2b7-f690-436e-aafc-6521bb2f5514",
   "metadata": {
    "language": "python",
    "name": "cell5",
    "collapsed": false
   },
   "outputs": [],
   "source": "# Define how to retrieve the presigned URL\nfile_url = call_builtin('GET_PRESIGNED_URL', lit('@IMAGE_FILES'), col('RELATIVE_PATH'))\n\n# Define vLLM generation arguments\ngeneration_args = object_construct(\n    lit('max_length'),lit(2500),\n    lit('top_p'),lit(0.8)\n)\n\n# Define vLLM arguments\nargs = object_construct(\n    lit('file_url'),file_url,\n    lit('stream'),lit(False),\n    lit('generation_args'),generation_args\n)\n\n# Define vLLM prompt\nprompt = object_construct(\n    lit('prompt'),lit('Who is this?'),\n    lit('args'),args\n)\n\nmodel = call_udf('GLM_V4_9B',prompt)",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "3a468daa-2b1f-4abf-a3b5-f63d4944131e",
   "metadata": {
    "name": "cell10",
    "collapsed": false
   },
   "source": "## Apply Model to Data"
  },
  {
   "cell_type": "code",
   "id": "a2c02476-3b5d-4c6a-8048-e8cf034bcb95",
   "metadata": {
    "language": "python",
    "name": "cell11",
    "collapsed": false
   },
   "outputs": [],
   "source": "analysis_df = files_df.with_column('VLLM_OUTPUT', model)\nanalysis_df = analysis_df.with_column('PRESIGNED_URL', file_url)\nanalysis_df = analysis_df.with_column('LLM_OUTPUT_TEXT', col('VLLM_OUTPUT')['LLM_OUTPUT_TEXT'].cast('string')).cache_result()\nanalysis_df[['RELATIVE_PATH','LLM_OUTPUT_TEXT']]",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "f673afeb-ebe0-40b2-b2c2-39857c040a89",
   "metadata": {
    "name": "cell12",
    "collapsed": false
   },
   "source": "## Visualize Results"
  },
  {
   "cell_type": "code",
   "id": "a6975d85-3f6b-45d3-bacb-f3b3eea7ca0a",
   "metadata": {
    "language": "python",
    "name": "cell4",
    "collapsed": false
   },
   "outputs": [],
   "source": "for i, row in analysis_df.to_pandas().iterrows():\n    with st.container():\n        col1, col2 = st.columns([0.2,0.8])\n        with col1:\n            st.image(row['PRESIGNED_URL'], caption=row['RELATIVE_PATH'])\n        with col2:\n            st.markdown(row['LLM_OUTPUT_TEXT'])\n        st.markdown(\"---\")",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "3ac57243-2da3-4ee3-8e8f-82ab85fdf2c6",
   "metadata": {
    "name": "cell20",
    "collapsed": false
   },
   "source": "# Example: Score Multipage PDFs"
  },
  {
   "cell_type": "markdown",
   "id": "47b63962-2e0c-40cf-826a-cc7d60c81f29",
   "metadata": {
    "name": "cell13",
    "collapsed": false
   },
   "source": "## Retrieve Data"
  },
  {
   "cell_type": "code",
   "id": "795ebbf5-f815-447d-bdc9-a84cb4cd8601",
   "metadata": {
    "language": "python",
    "name": "cell3",
    "collapsed": false
   },
   "outputs": [],
   "source": "files_df = session.sql('SELECT * FROM DIRECTORY(@IMAGE_FILES)').filter(col('RELATIVE_PATH').startswith('pdfs/')).limit(2).cache_result()\n# Define which pages of the PDF you want to score\nfrom_page = 18\nto_page = 26\nfiles_df = files_df.cross_join(session.range(from_page, to_page, 1))\nfiles_df",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "3a7beee6-25e1-4b86-8e6b-9dfacb626f08",
   "metadata": {
    "name": "cell21",
    "collapsed": false
   },
   "source": "## Define Prompt"
  },
  {
   "cell_type": "code",
   "id": "70505144-ce9c-4191-8500-1e074eb9385e",
   "metadata": {
    "language": "python",
    "name": "cell14",
    "collapsed": false
   },
   "outputs": [],
   "source": "# Define how to retrieve the presigned URL\nfile_url = call_builtin('GET_PRESIGNED_URL', lit('@IMAGE_FILES'), col('RELATIVE_PATH'))\n\n# Define vLLM generation arguments\ngeneration_args = object_construct(\n    lit('max_length'),lit(2500),\n    lit('top_p'),lit(0.8)\n)\n\n# Define vLLM arguments\nargs = object_construct(\n    lit('file_url'),file_url,\n    lit('stream'),lit(False),\n    lit('pdf_page'),col('ID'),\n    lit('return_image_base64'),lit(True), # make sure to return pdf pages as base64 images so we can visualize them in this notebooks\n    lit('generation_args'),generation_args\n)\n\n# Define vLLM prompt\nprompt = object_construct(\n    lit('prompt'),lit('Explain the graphs in this slide to me in maximum 5 sentences.'),\n    lit('args'),args\n)\n\nmodel = call_udf('GLM_V4_9B',prompt)",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "41c0b2cc-96dd-4aca-a52c-405cd52804c1",
   "metadata": {
    "name": "cell15",
    "collapsed": false
   },
   "source": "## Apply Model to Data"
  },
  {
   "cell_type": "code",
   "id": "87308853-2b3e-4e27-b3f1-35cb15590482",
   "metadata": {
    "language": "python",
    "name": "cell18",
    "collapsed": false
   },
   "outputs": [],
   "source": "analysis_df = files_df.with_column('VLLM_OUTPUT', model).cache_result()\nanalysis_df = analysis_df.with_column('PRESIGNED_URL', file_url)\nanalysis_df = analysis_df.with_column('LLM_OUTPUT_TEXT', col('VLLM_OUTPUT')['LLM_OUTPUT_TEXT'].cast('string'))\nanalysis_df = analysis_df.with_column('BASE64_IMAGE', col('VLLM_OUTPUT')['base64_image'].cast('string')).cache_result()\nanalysis_df = analysis_df.order_by('ID')\nanalysis_df",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "91c0c638-451b-4b25-90b3-b430b0410444",
   "metadata": {
    "name": "cell19",
    "collapsed": false
   },
   "source": "## Visualize Results"
  },
  {
   "cell_type": "code",
   "id": "5fa260c6-0d37-4fdc-8007-797f65a38c63",
   "metadata": {
    "language": "python",
    "name": "cell17",
    "collapsed": false
   },
   "outputs": [],
   "source": "from PIL import Image\nimport base64\nfrom io import BytesIO\ndef base64_to_pil_image(base64_str: str) -> Image.Image:\n    # Decode the base64 string to bytes\n    img_byte_data = base64.b64decode(base64_str)\n    # Create a BytesIO buffer from the byte data\n    img_buffer = BytesIO(img_byte_data)\n    # Open the image from the buffer using PIL\n    image = Image.open(img_buffer)\n    return image\n    \nfor i, row in analysis_df.to_pandas().iterrows():\n    with st.container():\n        col1, col2 = st.columns([0.5,0.5])\n        with col1:\n            image = base64_to_pil_image(row['BASE64_IMAGE'])\n            st.image(image, caption=f\"{row['RELATIVE_PATH']} - Page: {row['ID']}\")\n        with col2:\n            st.markdown(row['LLM_OUTPUT_TEXT'])\n        st.markdown(\"---\")",
   "execution_count": null
  }
 ]
}