{
 "metadata": {
  "kernelspec": {
   "display_name": "Streamlit Notebook",
   "name": "streamlit"
  }
 },
 "nbformat_minor": 5,
 "nbformat": 4,
 "cells": [
  {
   "cell_type": "markdown",
   "id": "01b98b46-36f4-4778-b0f5-c30ef5773861",
   "metadata": {
    "name": "cell6",
    "collapsed": false
   },
   "source": "# Multimodal Model in Snowflake"
  },
  {
   "cell_type": "markdown",
   "id": "dc574e25-80f6-4425-ae78-1c010dd74595",
   "metadata": {
    "name": "cell7",
    "collapsed": false
   },
   "source": "## Imports"
  },
  {
   "cell_type": "code",
   "id": "3775908f-ca36-4846-8f38-5adca39217f2",
   "metadata": {
    "language": "python",
    "name": "cell1",
    "collapsed": false
   },
   "source": "from snowflake.snowpark.functions import call_udf, call_builtin, col, lit, object_construct, regexp_replace\n\n# Import python packages\nimport streamlit as st\nimport pandas as pd\nfrom io import BytesIO\nimport base64\n\n# We can also use Snowpark for our analyses!\nfrom snowflake.snowpark.context import get_active_session\nsession = get_active_session()",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "5344e5de-3dda-4bdf-b1a0-db8d1591eaa9",
   "metadata": {
    "name": "cell16",
    "collapsed": false
   },
   "source": "# Example: Describe a list of Images"
  },
  {
   "cell_type": "markdown",
   "id": "58733fb6-6c86-4f5b-9500-8b7de26f1c3e",
   "metadata": {
    "name": "cell8",
    "collapsed": false
   },
   "source": "## Retrieve Data"
  },
  {
   "cell_type": "code",
   "id": "8ec91f4a-3bd2-4bbe-aea3-7b5f6b0bb4bd",
   "metadata": {
    "language": "python",
    "name": "cell2",
    "collapsed": false
   },
   "outputs": [],
   "source": "files_df = session.sql('SELECT * FROM DIRECTORY(@IMAGE_FILES)').filter(col('RELATIVE_PATH').startswith('celebs/')).limit(2).cache_result()\nfiles_df",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "e035d7da-b248-44d4-b92a-a33c9d8a2eda",
   "metadata": {
    "name": "cell9",
    "collapsed": false
   },
   "source": "## Define Prompt"
  },
  {
   "cell_type": "code",
   "id": "d992f2b7-f690-436e-aafc-6521bb2f5514",
   "metadata": {
    "language": "python",
    "name": "cell5",
    "collapsed": false
   },
   "outputs": [],
   "source": "# Define how to retrieve the presigned URL\nfile_url = call_builtin('GET_PRESIGNED_URL', lit('@IMAGE_FILES'), col('RELATIVE_PATH'))\n\n# Define vLLM generation arguments\ngeneration_args = object_construct(\n    lit('max_length'),lit(2500),\n    lit('top_p'),lit(0.8)\n)\n\n# Define vLLM arguments\nargs = object_construct(\n    lit('file_url'),file_url,\n    lit('stream'),lit(False),\n    lit('generation_args'),generation_args\n)\n\n# Define vLLM prompt\nprompt = object_construct(\n    lit('prompt'),lit('Who is this?'),\n    lit('args'),args\n)\n\nmodel = call_udf('GLM_V4_9B',prompt)",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "3a468daa-2b1f-4abf-a3b5-f63d4944131e",
   "metadata": {
    "name": "cell10",
    "collapsed": false
   },
   "source": "## Apply Model to Data"
  },
  {
   "cell_type": "code",
   "id": "a2c02476-3b5d-4c6a-8048-e8cf034bcb95",
   "metadata": {
    "language": "python",
    "name": "cell11",
    "collapsed": false
   },
   "outputs": [],
   "source": "analysis_df = files_df.with_column('VLLM_OUTPUT', model)\nanalysis_df = analysis_df.with_column('PRESIGNED_URL', file_url)\nanalysis_df = analysis_df.with_column('LLM_OUTPUT_TEXT', col('VLLM_OUTPUT')['LLM_OUTPUT_TEXT'].cast('string')).cache_result()\nanalysis_df[['RELATIVE_PATH','LLM_OUTPUT_TEXT']]",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "f673afeb-ebe0-40b2-b2c2-39857c040a89",
   "metadata": {
    "name": "cell12",
    "collapsed": false
   },
   "source": "## Visualize Results"
  },
  {
   "cell_type": "code",
   "id": "a6975d85-3f6b-45d3-bacb-f3b3eea7ca0a",
   "metadata": {
    "language": "python",
    "name": "cell4",
    "collapsed": false
   },
   "outputs": [],
   "source": "for i, row in analysis_df.to_pandas().iterrows():\n    with st.container():\n        col1, col2 = st.columns([0.2,0.8])\n        with col1:\n            st.image(row['PRESIGNED_URL'], caption=row['RELATIVE_PATH'])\n        with col2:\n            st.markdown(row['LLM_OUTPUT_TEXT'])\n        st.markdown(\"---\")",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "3ac57243-2da3-4ee3-8e8f-82ab85fdf2c6",
   "metadata": {
    "name": "cell20",
    "collapsed": false
   },
   "source": "# Example: Score Multipage PDFs"
  },
  {
   "cell_type": "markdown",
   "id": "47b63962-2e0c-40cf-826a-cc7d60c81f29",
   "metadata": {
    "name": "cell13",
    "collapsed": false
   },
   "source": "## Retrieve Data"
  },
  {
   "cell_type": "code",
   "id": "795ebbf5-f815-447d-bdc9-a84cb4cd8601",
   "metadata": {
    "language": "python",
    "name": "cell3",
    "collapsed": false
   },
   "outputs": [],
   "source": "files_df = session.sql('SELECT * FROM DIRECTORY(@IMAGE_FILES)').filter(col('RELATIVE_PATH').startswith('pdfs/')).limit(2).cache_result()\n# Define which pages of the PDF you want to score\nfrom_page = 18\nto_page = 26\nfiles_df = files_df.cross_join(session.range(from_page, to_page, 1))\nfiles_df",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "3a7beee6-25e1-4b86-8e6b-9dfacb626f08",
   "metadata": {
    "name": "cell21",
    "collapsed": false
   },
   "source": "## Define Prompt"
  },
  {
   "cell_type": "code",
   "id": "70505144-ce9c-4191-8500-1e074eb9385e",
   "metadata": {
    "language": "python",
    "name": "cell14",
    "collapsed": false
   },
   "outputs": [],
   "source": "# Define how to retrieve the presigned URL\nfile_url = call_builtin('GET_PRESIGNED_URL', lit('@IMAGE_FILES'), col('RELATIVE_PATH'))\n\n# Define vLLM generation arguments\ngeneration_args = object_construct(\n    lit('max_length'),lit(2500),\n    lit('top_p'),lit(0.8)\n)\n\n# Define vLLM arguments\nargs = object_construct(\n    lit('file_url'),file_url,\n    lit('stream'),lit(False),\n    lit('pdf_page'),col('ID'),\n    lit('return_image_base64'),lit(True), # make sure to return pdf pages as base64 images so we can visualize them in this notebooks\n    lit('generation_args'),generation_args\n)\n\n# Define vLLM prompt\nprompt = object_construct(\n    lit('prompt'),lit('Explain the graphs in this slide to me in maximum 5 sentences.'),\n    lit('args'),args\n)\n\nmodel = call_udf('GLM_V4_9B',prompt)",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "41c0b2cc-96dd-4aca-a52c-405cd52804c1",
   "metadata": {
    "name": "cell15",
    "collapsed": false
   },
   "source": "## Apply Model to Data"
  },
  {
   "cell_type": "code",
   "id": "87308853-2b3e-4e27-b3f1-35cb15590482",
   "metadata": {
    "language": "python",
    "name": "cell18",
    "collapsed": false
   },
   "outputs": [],
   "source": "analysis_df = files_df.with_column('VLLM_OUTPUT', model).cache_result()\nanalysis_df = analysis_df.with_column('PRESIGNED_URL', file_url)\nanalysis_df = analysis_df.with_column('LLM_OUTPUT_TEXT', col('VLLM_OUTPUT')['LLM_OUTPUT_TEXT'].cast('string'))\nanalysis_df = analysis_df.with_column('BASE64_IMAGE', col('VLLM_OUTPUT')['base64_image'].cast('string')).cache_result()\nanalysis_df = analysis_df.order_by('ID')\nanalysis_df",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "91c0c638-451b-4b25-90b3-b430b0410444",
   "metadata": {
    "name": "cell19",
    "collapsed": false
   },
   "source": "## Visualize Results"
  },
  {
   "cell_type": "code",
   "id": "5fa260c6-0d37-4fdc-8007-797f65a38c63",
   "metadata": {
    "language": "python",
    "name": "cell17",
    "collapsed": false
   },
   "outputs": [],
   "source": "from PIL import Image\nimport base64\nfrom io import BytesIO\ndef base64_to_pil_image(base64_str: str) -> Image.Image:\n    # Decode the base64 string to bytes\n    img_byte_data = base64.b64decode(base64_str)\n    # Create a BytesIO buffer from the byte data\n    img_buffer = BytesIO(img_byte_data)\n    # Open the image from the buffer using PIL\n    image = Image.open(img_buffer)\n    return image\n    \nfor i, row in analysis_df.to_pandas().iterrows():\n    with st.container():\n        col1, col2 = st.columns([0.5,0.5])\n        with col1:\n            image = base64_to_pil_image(row['BASE64_IMAGE'])\n            st.image(image, caption=f\"{row['RELATIVE_PATH']} - Page: {row['ID']}\")\n        with col2:\n            st.markdown(row['LLM_OUTPUT_TEXT'])\n        st.markdown(\"---\")",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "deb1a8f8-f90f-473b-80da-201a714084be",
   "metadata": {
    "name": "cell22",
    "collapsed": false
   },
   "source": "# Example: Extracting Attributes from Images"
  },
  {
   "cell_type": "markdown",
   "id": "989eb54a-e7e1-427f-b8fb-74ab444d2c3b",
   "metadata": {
    "name": "cell25",
    "collapsed": false
   },
   "source": "### Retrieve Data"
  },
  {
   "cell_type": "code",
   "id": "0ec43dba-530a-4218-ab59-1997a5b46b96",
   "metadata": {
    "language": "python",
    "name": "cell23",
    "collapsed": false
   },
   "outputs": [],
   "source": "files_df = session.sql('SELECT * FROM DIRECTORY(@IMAGE_FILES)').filter(col('RELATIVE_PATH').startswith('celebs/')).limit(2).cache_result()\nfiles_df",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "f7ab3a28-f697-427f-9083-01f2cd3970d6",
   "metadata": {
    "name": "cell26",
    "collapsed": false
   },
   "source": "### Define Prompt"
  },
  {
   "cell_type": "code",
   "id": "c0d1f650-c4c9-4e12-9eb1-92640f6de7ce",
   "metadata": {
    "language": "python",
    "name": "cell24"
   },
   "outputs": [],
   "source": "# Define how to retrieve the presigned URL\nfile_url = call_builtin('GET_PRESIGNED_URL', lit('@IMAGE_FILES'), col('RELATIVE_PATH'))\n\n# Define vLLM generation arguments\ngeneration_args = object_construct(\n    lit('max_length'),lit(2500),\n    lit('top_p'),lit(0.8)\n)\n\n# Define vLLM arguments\nargs = object_construct(\n    lit('file_url'),file_url,\n    lit('stream'),lit(False),\n    lit('generation_args'),generation_args\n)\n\n# Define vLLM prompt\nprompt = object_construct(\n    lit('prompt'),lit('Given this picture, return a JSON like this: {haircolor:haircolor, gender:gender, approx_age:approx_age}.'),\n    lit('args'),args\n)\n\nmodel = call_udf('GLM_V4_9B',prompt)",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "2dd01224-e780-46bf-9eee-df182f5dc19a",
   "metadata": {
    "name": "cell27",
    "collapsed": false
   },
   "source": "## Apply Model to Data"
  },
  {
   "cell_type": "code",
   "id": "ce152e13-567a-4463-9435-326e900b3940",
   "metadata": {
    "language": "python",
    "name": "cell28"
   },
   "outputs": [],
   "source": "analysis_df = files_df.with_column('VLLM_OUTPUT', model)\nanalysis_df = analysis_df.with_column('PRESIGNED_URL', file_url)\nanalysis_df = analysis_df.with_column('LLM_OUTPUT_TEXT', col('VLLM_OUTPUT')['LLM_OUTPUT_TEXT'])\nanalysis_df = analysis_df.with_column(\n    'LLM_OUTPUT_JSON', \n    call_builtin('try_parse_json', regexp_replace(\"LLM_OUTPUT_TEXT\", r\"(^[^{}]*|[^{}]*$)\", '', 1, 0, 's'))).cache_result()\nanalysis_df[['RELATIVE_PATH','LLM_OUTPUT_JSON']]",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "3f465d6e-d084-4114-91b0-f552d215aaa2",
   "metadata": {
    "name": "cell30",
    "collapsed": false
   },
   "source": "## Visualize Results"
  },
  {
   "cell_type": "code",
   "id": "5972c5f1-8618-4592-9929-6b0ac25a66cb",
   "metadata": {
    "language": "python",
    "name": "cell29"
   },
   "outputs": [],
   "source": "for i, row in analysis_df.to_pandas().iterrows():\n    with st.container():\n        col1, col2 = st.columns([0.2,0.8])\n        with col1:\n            st.image(row['PRESIGNED_URL'], caption=row['FILE_URL'], use_column_width=True)\n        with col2:\n            st.json(row['LLM_OUTPUT_JSON'])\n        st.markdown(\"---\")",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "d68c4d88-447d-4499-92cf-5daa37ab67ca",
   "metadata": {
    "name": "cell31",
    "collapsed": false
   },
   "source": "# Example: Explaining Graphs"
  },
  {
   "cell_type": "markdown",
   "id": "b7f4ca3d-a23d-41b8-845f-cc9db3f9af83",
   "metadata": {
    "name": "cell34",
    "collapsed": false
   },
   "source": "## Generate a graph and save figure as base64 image"
  },
  {
   "cell_type": "code",
   "id": "233a1dc4-cc74-430d-b609-7f2c95dbdb8f",
   "metadata": {
    "language": "python",
    "name": "cell32"
   },
   "outputs": [],
   "source": "import matplotlib.pyplot as plt\n\n# Data for the revenue by month in 2024\nmonths = [\n    \"January\", \"February\", \"March\", \"April\", \"May\", \"June\",\n    \"July\", \"August\", \"September\", \"October\", \"November\", \"December\"\n]\nrevenue = [1000, 1500, 2000, 2500, 3000, 3500, 4000, 4500, 5000, 5500, 6000, 6500]\n\n# Create a bar plot\nplt.figure(figsize=(5, 3))\nplt.bar(months, revenue, color='blue')\n\n# Add titles and labels\nplt.title(\"Revenue by Month for the Year 2024\")\nplt.xlabel(\"Month\")\nplt.ylabel(\"Revenue (in USD)\")\nplt.xticks(rotation=45)\nplt.ylim(0, 7000)\n\n# Save the figure to a BytesIO object\nbuf = BytesIO()\nplt.savefig(buf, format='png')\nbuf.seek(0)\n\n# Convert the BytesIO object to a base64 string\nimg_base64 = base64.b64encode(buf.read()).decode('utf-8')\n\n# Close the buffer\nbuf.close()",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "f63caffd-90cf-4021-8b1f-fbd9214ce7a9",
   "metadata": {
    "name": "cell35",
    "collapsed": false
   },
   "source": "## Apply Model to Data"
  },
  {
   "cell_type": "code",
   "id": "9173e9e4-affa-4e94-8169-fccae1eaea73",
   "metadata": {
    "language": "python",
    "name": "cell36"
   },
   "outputs": [],
   "source": "# Define vLLM generation arguments\ngeneration_args = object_construct(\n    lit('max_length'),lit(2500),\n    lit('top_p'),lit(0.8)\n)\n\n# Define vLLM arguments\nargs = object_construct(\n    lit('base64_image_string'),lit(img_base64),\n    lit('stream'),lit(False),\n    lit('generation_args'),generation_args\n)\n\n# Define vLLM prompt\nprompt = object_construct(\n    lit('prompt'),lit('How much did the revenue grew from January to December in 2024?'),\n    lit('args'),args\n)\n\nmodel = call_udf('GLM_V4_9B',prompt)",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "26799c40-ef7b-430b-9e96-73d8901272e9",
   "metadata": {
    "language": "python",
    "name": "cell38"
   },
   "outputs": [],
   "source": "plot_explanation_df = session.range(1).with_column('VLLM_OUTPUT', model).cache_result()\nplot_explanation_df = plot_explanation_df.with_column('LLM_OUTPUT_TEXT', col('VLLM_OUTPUT')['LLM_OUTPUT_TEXT'].cast('string')).cache_result()\nplot_explanation_df",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "f424c68f-a455-41d3-b981-0fc20d0b721c",
   "metadata": {
    "language": "python",
    "name": "cell37"
   },
   "outputs": [],
   "source": "st.info(plot_explanation_df[['LLM_OUTPUT_TEXT']].collect()[0]['LLM_OUTPUT_TEXT'])",
   "execution_count": null
  }
 ]
}