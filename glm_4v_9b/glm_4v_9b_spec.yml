spec:
  container:
  - name: glm-4v-9b-service-container
    image: /llm_db/public/image_repository/glm_4v_9b_service:latest
    resources:
      requests:
        nvidia.com/gpu: 1
      limits:
        nvidia.com/gpu: 1
    env:
      HUGGINGFACE_MODEL: THUDM/glm-4v-9b
      SNOWFLAKE_WAREHOUSE: COMPUTE_WH
      SNOWFLAKE_DATABASE: LLM_DB
      SNOWFLAKE_SCHEMA: PUBLIC
      SNOWFLAKE_ROLE: LLM_ROLE
    volumeMounts:
      - name: llm-models
        mountPath: /llm_models
  endpoint:
  - name: api
    port: 9000
    public: true
  - name: streamlit
    port: 9001
    public: true
  volume:
  - name: llm-models
    source: "@LLM_DB.PUBLIC.LLM_MODELS"
    uid: 1000
    gid: 1000